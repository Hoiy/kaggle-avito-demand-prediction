{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model - NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Vfabwzu_xQQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dded294-338f-4cb8-8015-f1fba50f6f9f"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dotenv\n",
        "from scipy import sparse\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "dotenv.load_dotenv('.env')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "62RQrn89xogg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "5a04b8c9-f765-49e8-8871-52c2798faae6"
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!gsutil rsync gs://{os.environ['GCP_BUCKET']}/data data\n",
        "!kaggle competitions download -f sample_submission.csv --path ./data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building synchronization state...\n",
            "Starting synchronization...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/sample_submission.csv...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/test.csv.zip...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/test_description_lsa.snappy.parquet...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/test_description_tfidf.npz...\n",
            "| [4 files][355.8 MiB/355.8 MiB]   57.0 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m -o ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/test_prep.snappy.parquet...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/test_title_lsa.snappy.parquet...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/test_title_tfidf.npz...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/tfidf_feature_names.pl...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/train.csv.zip...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/train_description_lsa.snappy.parquet...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/train_description_tfidf.npz...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/train_prep.snappy.parquet...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying gs://kaggle-195720-avito-demand-prediction/data/train_title_lsa.snappy.parquet...\n",
            "Copying gs://kaggle-195720-avito-demand-prediction/data/train_title_tfidf.npz...\n",
            "| [14 files][  2.3 GiB/  2.3 GiB]   55.8 MiB/s                                  \n",
            "Operation completed over 14 objects/2.3 GiB.                                     \n",
            "Using competition: avito-demand-prediction\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s80J_cizUQG1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7974f4d9-2e50-4ca2-c66e-db6a945238d1"
      },
      "cell_type": "code",
      "source": [
        "cat_cols = [\n",
        "    'image_top_1', \n",
        "    'region_code', \n",
        "    'city_code', \n",
        "    'parent_category_name_code', \n",
        "    'category_name_code', \n",
        "    'user_type_code', \n",
        "    'param_1_code', \n",
        "    'param_2_code', \n",
        "    'param_3_code',\n",
        "    'user_id_code',\n",
        "    'item_seq_number_code',\n",
        "    'activation_date_weekday_code',\n",
        "    'activation_date_month_code',\n",
        "    'activation_date_day_code'\n",
        "]\n",
        "cont_cols = ['price_std', 'title_length', 'title_space_count', 'description_length', 'description_space_count']\n",
        "sparse_cols = \n",
        "\n",
        "\n",
        "def load_data(t):\n",
        "    df = pd.read_parquet('./data/%s_prep.snappy.parquet'%t, columns=cat_cols+cont_cols)\n",
        "\n",
        "    prep = sparse.csr_matrix(df.values)\n",
        "    \n",
        "    title_tfidf = sparse.load_npz('./data/%s_title_tfidf.npz'%t)\n",
        "    description_tfidf = sparse.load_npz('./data/%s_description_tfidf.npz'%t)\n",
        "    tfidf_features = pickle.load(open('./data/tfidf_feature_names.pl', 'rb'))\n",
        "\n",
        "    feature_names = df.columns.tolist() + ['title_%s'%f for f in tfidf_features] + ['description_%s'%f for f in tfidf_features]\n",
        "    features = sparse.hstack([prep, title_tfidf, description_tfidf])\n",
        "\n",
        "    return features, feature_names"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FY5p9vjFi8iO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8395cfb2-43c2-4b93-85f1-a064760aa8ab"
      },
      "cell_type": "code",
      "source": [
        "# train = pd.read_parquet('./data/train_prep.snappy.parquet')\n",
        "# test = pd.read_parquet('./data/test_prep.snappy.parquet')\n",
        "# submission = pd.read_csv('./data/sample_submission.csv')\n",
        "X_train, X_cols = load_data('train')\n",
        "y_train, y_cols = pd.read_parquet('./data/train_prep.snappy.parquet', columns=['deal_probability'])['deal_probability'], ['deal_probability']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dartndvrZkxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8f33a668-383b-479d-e3f7-58f4f88f779c"
      },
      "cell_type": "code",
      "source": [
        "emb_size = [\n",
        "    8,\n",
        "    2,\n",
        "    2,\n",
        "    2,\n",
        "    2,\n",
        "    2,\n",
        "    2,\n",
        "    2,\n",
        "    2,\n",
        "    8,\n",
        "    8,\n",
        "    2,\n",
        "    2,\n",
        "    2\n",
        "]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HGt6jROdledZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "4fb35034-2eb4-47cf-ebe0-1722425c5bd3"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input, Flatten, Activation, Reshape, Add, Average\n",
        "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout, GRU, Conv1D, Reshape, MaxPooling1D, Concatenate, Dot\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.regularizers import l2, l1\n",
        "from keras.constraints import non_neg, unit_norm\n",
        "import keras.backend as K\n",
        "from keras.metrics import mse\n",
        "import tensorflow as tf\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "DROPOUT = 0.2\n",
        "REGULARIZATION = 1e-5\n",
        "EMB_SIZE = 1\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    # bug when K.sqrt(mse(y_true, y_pred))\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(y_true, y_pred))))\n",
        "  \n",
        "def deal_cat_pred(deal_cat, hidden, zeros, ones):\n",
        "  if deal_cat == 0:\n",
        "      return zeros\n",
        "  elif deal_cat == 1:\n",
        "    output = Dense(8, activation=\"relu\")(hidden)\n",
        "    output = Dense(8, activation=\"relu\")(output)\n",
        "    return Dense(1, activation=\"sigmoid\")(output)\n",
        "  elif deal_cat == 2:\n",
        "    output = Dense(8, activation=\"relu\")(hidden)\n",
        "    output = Dense(8, activation=\"relu\")(output)\n",
        "    return Dense(1, activation=\"sigmoid\")(output)\n",
        "  else:\n",
        "    return ones\n",
        "  \n",
        "\n",
        "def build_model():\n",
        "#     zeros = Input(shape=(1, ))\n",
        "#     ones = Input(shape=(1, ))\n",
        "    cat_inputs = []\n",
        "    cat_embs = []\n",
        "    for cat, s in zip(cat_cols, emb_size):\n",
        "      inp = Input(shape=(1,), name=cat)\n",
        "      emb = Embedding(train[cat].max()+1, s, embeddings_regularizer=l2(REGULARIZATION))(inp)\n",
        "      emb = Flatten()(emb)\n",
        "      emb = Activation('tanh')(emb)\n",
        "      \n",
        "      cat_inputs.append(inp)\n",
        "      cat_embs.append(emb)\n",
        "    \n",
        "    \n",
        "    cont_inputs = []\n",
        "    cont_embs = []\n",
        "    for col in cont_cols:\n",
        "      inp = Input(shape=(1,), name=col)\n",
        "      emb = Dense(4,activation='tanh')(inp)\n",
        "      \n",
        "      cont_inputs.append(inp)\n",
        "      cont_embs.append(emb)\n",
        "      \n",
        "    \n",
        "    emb = Concatenate()(cat_embs + cont_embs)\n",
        "    \n",
        "    vec = Reshape((-1, 1))(emb)    \n",
        "    outter = Flatten()(Dot(-1)([vec, vec]))\n",
        "    # outter = Flatten()(Dot(-1)([vec, outter]))\n",
        "    \n",
        "    emb = Concatenate()([emb, outter])\n",
        "    \n",
        "#     preds = []\n",
        "    \n",
        "#     for i in range(10):\n",
        "#       pred = Dropout(DROPOUT)(emb)\n",
        "#       pred = Dense(1, activation='sigmoid')(pred)\n",
        "#       preds.append(pred)\n",
        "      \n",
        "#     out = Average()(preds)\n",
        "\n",
        "    emb = Dropout(DROPOUT)(emb)\n",
        "    emb = Dense(64, activation='selu')(emb)\n",
        "    emb = Dropout(DROPOUT)(emb)\n",
        "    out = Dense(1, activation='sigmoid')(emb)\n",
        "    \n",
        "    model = Model(inputs=cat_inputs + cont_inputs, outputs=out)\n",
        "    model.compile(loss=rmse,\n",
        "                  optimizer='adam',\n",
        "#                   optimizer='sgd',\n",
        "#                   optimizer='adadelta',\n",
        "                  metrics=[rmse])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c9fd52a66736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-c9fd52a66736>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mcat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcat_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREGULARIZATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'emb_size' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UbUoAlt2pI88",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_period = ((train['activation_date'] >= '2017-03-15') & (train['activation_date'] <= '2017-03-16')) |\\\n",
        "  ((train['activation_date'] >= '2017-03-22') & (train['activation_date'] <= '2017-03-23'))\n",
        "train_period = ~val_period\n",
        "\n",
        "BATCH_SIZE = 4096 * 2\n",
        "EPOCHS = 20000\n",
        "FILE_PATH = 'model.p5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(FILE_PATH, monitor='val_rmse', save_best_only=True)\n",
        "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=2)\n",
        "callbacks_list = [checkpoint, early] #early"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9X18OYRFygj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "\n",
        "# k_fold = KFold(n_splits=5, shuffle=True)\n",
        "# model = KerasRegressor(build_model, batch_size=BATCH_SIZE)\n",
        "# metrics = cross_val_score(\n",
        "#     model, \n",
        "#     [train[col] for col in cat_cols] + [train['price_std']], \n",
        "#     train['deal_probability'], \n",
        "#     cv=k_fold,\n",
        "#     n_jobs=1,\n",
        "#     fit_params={\n",
        "#         'validation_split': 0.2,\n",
        "#         'shuffle': True,\n",
        "#         'batch_size': BATCH_SIZE,\n",
        "#         'epochs': EPOCHS,\n",
        "#         'callbacks': callbacks_list\n",
        "#     }\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "koCdCQSbN9ni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "7b24631a-23ad-43ef-de65-02cb22353675"
      },
      "cell_type": "code",
      "source": [
        "# Full training\n",
        "# train_inp = [train[train_period][col] for col in cat_cols] + [train[train_period][col] for col in cont_cols]\n",
        "# val_inp = [train[val_period][col] for col in cat_cols] + [train[val_period][col] for col in cont_cols]\n",
        "\n",
        "BATCH_SIZE = 4096 // 4\n",
        "\n",
        "# model = KerasRegressor(build_model, batch_size=BATCH_SIZE)\n",
        "# model.fit(train_inp, train[train_period]['deal_probability'], **{\n",
        "#         'validation_data': (val_inp, train[val_period]['deal_probability']),\n",
        "#         'shuffle': True,\n",
        "#         'batch_size': BATCH_SIZE,\n",
        "#         'epochs': EPOCHS,\n",
        "#         'callbacks': callbacks_list\n",
        "# })\n",
        "model = KerasRegressor(build_model, batch_size=BATCH_SIZE)\n",
        "model.fit([train[col] for col in cat_cols] + [train[col] for col in cont_cols], train['deal_probability'], **{\n",
        "        'validation_split': 0.2,\n",
        "        'shuffle': True,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'epochs': EPOCHS,\n",
        "        'callbacks': callbacks_list\n",
        "})"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1202739 samples, validate on 300685 samples\n",
            "Epoch 1/20000\n",
            "1202739/1202739 [==============================] - 37s 31us/step - loss: 0.2380 - rmse: 0.2332 - val_loss: 0.2316 - val_rmse: 0.2266\n",
            "Epoch 2/20000\n",
            "  57344/1202739 [>.............................] - ETA: 31s - loss: 0.2286 - rmse: 0.2236"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1202739/1202739 [==============================] - 35s 29us/step - loss: 0.2300 - rmse: 0.2241 - val_loss: 0.2307 - val_rmse: 0.2248\n",
            "Epoch 3/20000\n",
            " 439296/1202739 [=========>....................] - ETA: 20s - loss: 0.2237 - rmse: 0.2175"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1202739/1202739 [==============================] - 35s 29us/step - loss: 0.2267 - rmse: 0.2205 - val_loss: 0.2311 - val_rmse: 0.2250\n",
            "Epoch 4/20000\n",
            " 582656/1202739 [=============>................] - ETA: 16s - loss: 0.2221 - rmse: 0.2157"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1202739/1202739 [==============================] - 35s 29us/step - loss: 0.2250 - rmse: 0.2186 - val_loss: 0.2312 - val_rmse: 0.2248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f10f0cf3f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "6Wyvt3p6O2g8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a1fe0dd-cd89-4a46-b84a-5c191fab22f0"
      },
      "cell_type": "code",
      "source": [
        "# from keras.models import load_model\n",
        "# model = load_model(FILE_PATH, custom_objects={'rmse': rmse})\n",
        "\n",
        "metric = model.score([train[col] for col in cat_cols] + [train[col] for col in cont_cols], train['deal_probability'])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1503424/1503424 [==============================] - 17s 11us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F8Vghc8bm0mP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d366437-0b4d-41a6-9578-b794ac7ad294"
      },
      "cell_type": "code",
      "source": [
        "metric"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.21996117967432383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "ndG63HKNYtCj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SUBMISSION_FILE='baseline.csv'\n",
        "SUBMISSION_MESSAGE='\"Baseline %f\"'%metric\n",
        "\n",
        "test['deal_probability'] = model.predict(\n",
        "    [test[col] for col in cat_cols] + [test[col] for col in cont_cols],\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "test[['item_id', 'deal_probability']].to_csv(SUBMISSION_FILE, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMgx2I7ntqhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf21ada9-1746-421e-8323-4a19d6a421a4"
      },
      "cell_type": "code",
      "source": [
        "len(test['item_id']) == len(submission['item_id'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "tCZluGeOZHVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3dede8c4-2a6e-497b-f3e3-2eb7683e4c7c"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -f '{SUBMISSION_FILE}' -m '{SUBMISSION_MESSAGE}'"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using competition: avito-demand-prediction\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.3.9.1 / client 1.3.8)\n",
            "Successfully submitted to Avito Demand Prediction Challenge"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9sGBq1HbjWoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a9ee7f95-374a-489b-db89-8ff218bacad0"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: kaggle competitions submit [-h] [-c COMPETITION] -f FILE_NAME -m\r\n",
            "                                  MESSAGE [-q]\r\n",
            "kaggle competitions submit: error: the following arguments are required: -f/--file, -m/--message\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8oHjisMgA1JF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88dac5a7-9490-4215-c3af-9c8a19f81539"
      },
      "cell_type": "code",
      "source": [
        "!echo \"{SUBMISSION_FILE}\""
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "baseline.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ywYx11DGA8bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "622726dc-11ee-4373-cc92-828f3904d248"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -m 'Baseline -0.22988' -f baseline.csv"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/local/bin/kaggle\", line 11, in <module>\r\n",
            "    sys.exit(main())\r\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/cli.py\", line 48, in main\r\n",
            "    out = args.func(**command_args)\r\n",
            "TypeError: competition_submit_cli() got an unexpected keyword argument 'file_name'\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dXeNdA-zBReI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f581197d-6336-4e9d-ddac-6d219c839762"
      },
      "cell_type": "code",
      "source": [
        "!pip freeze | grep kaggle"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle==1.3.9\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Di8gYaemCpmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f6e31cd-3699-4175-b22d-9a0d1b44954a"
      },
      "cell_type": "code",
      "source": [
        "!kaggle --version"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kaggle API 1.3.8\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VFuL24UJFROd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}